import { useState, useEffect, useRef } from "react";
import ROSLIB from "roslib";

const TalkTab = ({ ros }) => {
  const [messages, setMessages] = useState([]);
  const [inputText, setInputText] = useState("");
  const [isConnected, setIsConnected] = useState(false);
  const [currentBotMessage, setCurrentBotMessage] = useState(null);
  const [isRecording, setIsRecording] = useState(false);
  
  // ROS Topics
  const userInputTopic = useRef(null);
  const responseStreamTopic = useRef(null);
  const responseTopic = useRef(null);
  const audioTopic = useRef(null);
  const audioInputTopic = useRef(null);
  const transcriptionTopic = useRef(null);
  
  // éŸ³å£°éŒ²éŸ³ç”¨
  const mediaRecorderRef = useRef(null);
  const audioChunksRef = useRef([]);

  useEffect(() => {
    if (!ros) return;

    // ROS Topicã®åˆæœŸåŒ–
    userInputTopic.current = new ROSLIB.Topic({
      ros: ros,
      name: '/user_input',
      messageType: 'std_msgs/String'
    });

    responseStreamTopic.current = new ROSLIB.Topic({
      ros: ros,
      name: '/chatbot_response_stream',
      messageType: 'std_msgs/String'
    });

    responseTopic.current = new ROSLIB.Topic({
      ros: ros,
      name: '/chatbot_response',
      messageType: 'std_msgs/String'
    });

    audioTopic.current = new ROSLIB.Topic({
      ros: ros,
      name: '/tts_audio_data',
      messageType: 'std_msgs/UInt8MultiArray'
    });

    // éŸ³å£°å…¥åŠ›ç”¨ãƒˆãƒ”ãƒƒã‚¯
    audioInputTopic.current = new ROSLIB.Topic({
      ros: ros,
      name: '/audio_input',
      messageType: 'std_msgs/UInt8MultiArray'
    });

    // è»¢å†™çµæœå—ä¿¡ç”¨ãƒˆãƒ”ãƒƒã‚¯
    transcriptionTopic.current = new ROSLIB.Topic({
      ros: ros,
      name: '/transcription_result',
      messageType: 'std_msgs/String'
    });

    // ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¿œç­”ã®è³¼èª­
    responseStreamTopic.current.subscribe((message) => {
      handleStreamChunk(message.data);
    });

    // å®Œäº†å¿œç­”ã®è³¼èª­
    responseTopic.current.subscribe((message) => {
      handleCompleteResponse(message.data);
    });

    // TTSéŸ³å£°ã®è³¼èª­
    audioTopic.current.subscribe((message) => {
      handleAudioResponse(message.data);
    });

    // è»¢å†™çµæœã®è³¼èª­
    transcriptionTopic.current.subscribe((message) => {
      handleTranscriptionResult(message.data);
    });

    setIsConnected(true);

    return () => {
      responseStreamTopic.current?.unsubscribe();
      responseTopic.current?.unsubscribe();
      audioTopic.current?.unsubscribe();
      transcriptionTopic.current?.unsubscribe();
      setIsConnected(false);
    };
  }, [ros]);

  // ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒãƒ£ãƒ³ã‚¯ã®å‡¦ç†
  const handleStreamChunk = (chunk) => {
    setCurrentBotMessage(prev => {
      const newText = (prev?.text || '') + chunk;
      return {
        type: 'ai',
        text: newText,
        timestamp: prev?.timestamp || new Date().toLocaleTimeString("ja-JP", {
          hour: "2-digit",
          minute: "2-digit",
        }),
        streaming: true
      };
    });
  };

  // å®Œäº†å¿œç­”ã®å‡¦ç†
  const handleCompleteResponse = (response) => {
    if (currentBotMessage) {
      setMessages(prev => [...prev, { ...currentBotMessage, streaming: false }]);
      setCurrentBotMessage(null);
    }
  };

  // TTSéŸ³å£°ã®å‡¦ç†
  const handleAudioResponse = (audioData) => {
    try {
      // UInt8Arrayã‹ã‚‰éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å¾©å…ƒ
      const audioBytes = new Uint8Array(audioData);
      const audioBlob = new Blob([audioBytes], { type: 'audio/mpeg' });
      const audioUrl = URL.createObjectURL(audioBlob);
      const audio = new Audio(audioUrl);
      audio.play();
      
      // å†ç”Ÿçµ‚äº†å¾Œã«URLã‚’è§£æ”¾
      audio.onended = () => {
        URL.revokeObjectURL(audioUrl);
      };
    } catch (error) {
      console.error('éŸ³å£°å†ç”Ÿã‚¨ãƒ©ãƒ¼:', error);
    }
  };

  // è»¢å†™çµæœã®å‡¦ç†
  const handleTranscriptionResult = (text) => {
    if (text.trim()) {
      setInputText(text);
      // è‡ªå‹•é€ä¿¡ã™ã‚‹å ´åˆã¯ä»¥ä¸‹ã®ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆã‚’å¤–ã™
      // handleSendMessage(text);
    }
  };

  // ãƒ†ã‚­ã‚¹ãƒˆé€ä¿¡
  const handleSend = () => {
    if (!inputText.trim() || !isConnected) return;
    handleSendMessage(inputText);
    setInputText("");
  };

  const handleSendMessage = (text) => {
    // ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
    setMessages(prev => [...prev, {
      type: "user",
      text: text,
      timestamp: new Date().toLocaleTimeString("ja-JP", {
        hour: "2-digit",
        minute: "2-digit",
      }),
    }]);

    // ROSãƒˆãƒ”ãƒƒã‚¯ã«é€ä¿¡
    const message = new ROSLIB.Message({
      data: text
    });
    userInputTopic.current.publish(message);
  };

  const handleKeyPress = (e) => {
    if (e.key === "Enter" && !e.shiftKey) {
      e.preventDefault();
      handleSend();
    }
  };

  // éŸ³å£°éŒ²éŸ³é–‹å§‹
  const startRecording = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      
      mediaRecorderRef.current = new MediaRecorder(stream, { 
        mimeType: 'audio/webm' 
      });
      
      audioChunksRef.current = [];
      
      mediaRecorderRef.current.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunksRef.current.push(event.data);
        }
      };
      
      mediaRecorderRef.current.onstop = () => {
        const audioBlob = new Blob(audioChunksRef.current, { 
          type: 'audio/webm' 
        });
        sendAudioToROS(audioBlob);
        
        // ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’åœæ­¢
        stream.getTracks().forEach(track => track.stop());
      };
      
      mediaRecorderRef.current.start();
      setIsRecording(true);
      
    } catch (error) {
      console.error('éŒ²éŸ³é–‹å§‹ã‚¨ãƒ©ãƒ¼:', error);
      alert('ãƒã‚¤ã‚¯ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ãŒæ‹’å¦ã•ã‚Œã¾ã—ãŸ');
    }
  };

  // éŸ³å£°éŒ²éŸ³åœæ­¢
  const stopRecording = () => {
    if (mediaRecorderRef.current && isRecording) {
      mediaRecorderRef.current.stop();
      setIsRecording(false);
    }
  };

  // éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ROSã«é€ä¿¡
  const sendAudioToROS = async (audioBlob) => {
    try {
      const arrayBuffer = await audioBlob.arrayBuffer();
      const uint8Array = new Uint8Array(arrayBuffer);
      
      const message = new ROSLIB.Message({
        data: Array.from(uint8Array)
      });
      
      audioInputTopic.current.publish(message);
      
    } catch (error) {
      console.error('éŸ³å£°é€ä¿¡ã‚¨ãƒ©ãƒ¼:', error);
    }
  };

  // éŸ³å£°å…¥åŠ›ãƒœã‚¿ãƒ³ã®å‡¦ç†
  const handleVoiceInput = () => {
    if (isRecording) {
      stopRecording();
    } else {
      startRecording();
    }
  };

  return (
    <div className="h-full flex flex-col bg-white">
      {/* æ¥ç¶šçŠ¶æ…‹è¡¨ç¤º */}
      <div className="p-2 bg-gray-100 text-center">
        <span className={`text-sm ${isConnected ? 'text-green-600' : 'text-red-600'}`}>
          {isConnected ? 'ğŸŸ¢ ROSæ¥ç¶šä¸­' : 'ğŸ”´ ROSæœªæ¥ç¶š'}
        </span>
      </div>

      {/* ãƒãƒ£ãƒƒãƒˆå±¥æ­´ */}
      <div className="flex-1 overflow-y-auto p-4 space-y-4">
        {messages.map((msg, index) => (
          <div
            key={index}
            className={`flex ${
              msg.type === "ai" ? "justify-start" : "justify-end"
            }`}
          >
            {msg.type === "ai" && (
              <div className="mr-2 shrink-0">
                <div className="w-8 h-8 rounded-full bg-gray-200 flex items-center justify-center">
                  <span className="text-lg">ğŸ§ </span>
                </div>
              </div>
            )}
            <div
              className={`max-w-[70%] rounded-2xl px-4 py-3 ${
                msg.type === "ai"
                  ? "bg-amber-50 text-gray-800"
                  : "bg-cyan-100 text-gray-800"
              }`}
            >
              <p className="text-sm whitespace-pre-wrap">{msg.text}</p>
              <p className="text-xs text-gray-500 mt-1">{msg.timestamp}</p>
            </div>
            {msg.type === "user" && (
              <div className="ml-2 shrink-0">
                <div className="w-8 h-8 rounded-full bg-blue-500 flex items-center justify-center">
                  <img
                    src={"/nishidalab_logo.png"}
                    alt="logo"
                    className="w-8 h-8"
                  />
                </div>
              </div>
            )}
          </div>
        ))}
        
        {/* ç¾åœ¨å…¥åŠ›ä¸­ã®ãƒœãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ */}
        {currentBotMessage && (
          <div className="flex justify-start">
            <div className="mr-2 shrink-0">
              <div className="w-8 h-8 rounded-full bg-gray-200 flex items-center justify-center">
                <span className="text-lg">ğŸ§ </span>
              </div>
            </div>
            <div className="max-w-[70%] rounded-2xl px-4 py-3 bg-amber-50 text-gray-800 animate-pulse">
              <p className="text-sm whitespace-pre-wrap">{currentBotMessage.text}</p>
              <p className="text-xs text-gray-500 mt-1">
                {currentBotMessage.timestamp} (å…¥åŠ›ä¸­...)
              </p>
            </div>
          </div>
        )}
      </div>

      {/* å…¥åŠ›ã‚¨ãƒªã‚¢ */}
      <div className="border-t p-4 bg-white">
        <div className="flex gap-2">
          <input
            type="text"
            value={inputText}
            onChange={(e) => setInputText(e.target.value)}
            onKeyPress={handleKeyPress}
            placeholder="ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›..."
            className="flex-1 px-4 py-2 border border-gray-300 rounded-full focus:outline-none focus:border-blue-500"
            disabled={!isConnected}
          />
          <button
            onClick={handleSend}
            disabled={!isConnected || !inputText.trim()}
            className="w-10 h-10 bg-blue-500 text-white rounded-full flex items-center justify-center hover:bg-blue-600 transition-colors disabled:bg-gray-300"
          >
            â†’
          </button>
          <button 
            onClick={handleVoiceInput}
            disabled={!isConnected}
            className={`w-10 h-10 rounded-full flex items-center justify-center transition-colors ${
              isRecording 
                ? 'bg-red-500 text-white animate-pulse' 
                : 'bg-gray-200 text-gray-700 hover:bg-gray-300'
            } disabled:bg-gray-300`}
          >
            ğŸ¤
          </button>
        </div>
        
        {/* éŒ²éŸ³çŠ¶æ…‹è¡¨ç¤º */}
        {isRecording && (
          <div className="mt-2 text-center">
            <span className="text-sm text-red-600 animate-pulse">
              ğŸ”´ éŒ²éŸ³ä¸­... (ã‚¯ãƒªãƒƒã‚¯ã§åœæ­¢)
            </span>
          </div>
        )}
      </div>
    </div>
  );
};

export default TalkTab;
